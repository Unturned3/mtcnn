{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facenet_pytorch_c: avoid confusion with system default facenet_pytorch\n",
    "#from facenet_pytorch_c import MTCNN\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "# data handling\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# torchvision libs\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import PIL\n",
    "\n",
    "import utils_pnet as utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Available device: \" + str(device))\n",
    "\n",
    "# training hyperparameters\n",
    "learning_rate = 1e-3\n",
    "epochs = 200\n",
    "decay_step = [100, 150]\n",
    "decay_rate = 0.1\n",
    "opt = 'Adam'    # either Adam or SGD\n",
    "batch_size = 64\n",
    "\n",
    "# data loading parameters\n",
    "workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t, b_prob_t, b_box_t, _, _, x_v, b_prob_v, b_box_v, _, _ = utils.get_images(\n",
    "    img_path='/home/ubuntu/db_proc/db/images',\n",
    "    anno_path='/home/ubuntu/db_proc/db/annotations',\n",
    "    valid_percent=0.1, resize_shape=(48,48),\n",
    "    add_orig=False, gen_xtra_neg=True, gen_xtra_body=True, gen_xtra_face=False\n",
    ")\n",
    "\n",
    "print(len(x_t))\n",
    "print_freq = int(len(x_t)/batch_size - 5)\n",
    "print(\"print freq: {}\".format(print_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, 300, 20):\n",
    "    plt.imshow(x_t[i])\n",
    "    plt.show()\n",
    "    print(\"body: {}\".format(b_box_t[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "transform_valid = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "train_ds = utils.CIVDS_bnet(x_t, b_prob_t, b_box_t, trsfm=transform_train)\n",
    "\n",
    "valid_ds = utils.CIVDS_bnet(x_v, b_prob_v, b_box_v, trsfm=transform_valid)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=batch_size,\n",
    "    num_workers=workers, shuffle=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_ds, batch_size=batch_size,\n",
    "    num_workers=workers, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
    "        self.prelu1 = nn.PReLU(32)\n",
    "        self.pool1 = nn.MaxPool2d(3, 2, ceil_mode=True)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.prelu2 = nn.PReLU(64)\n",
    "        self.pool2 = nn.MaxPool2d(3, 2, ceil_mode=True)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        self.prelu3 = nn.PReLU(64)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2, ceil_mode=True)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=2)\n",
    "        self.prelu4 = nn.PReLU(128)\n",
    "        self.dense5 = nn.Linear(1152, 256)\n",
    "        self.prelu5 = nn.PReLU(256)\n",
    "        \n",
    "        self.dense6_1 = nn.Linear(256, 2)    # body prob\n",
    "        self.softmax6_1 = nn.Softmax(dim=1)\n",
    "        \n",
    "        self.dense6_2 = nn.Linear(256, 4)    # body bbox\n",
    "\n",
    "        self.training = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.prelu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.prelu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.prelu3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.prelu4(x)\n",
    "        x = self.dense5(x.view(x.shape[0], -1))\n",
    "        x = self.prelu5(x)\n",
    "        a = self.dense6_1(x)\n",
    "        a = self.softmax6_1(a)\n",
    "        b = self.dense6_2(x)\n",
    "        return a, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnet = BNet()\n",
    "bnet.train()\n",
    "bnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir=\"/home/ubuntu/tensorLog\") # tensorboard writer\n",
    "\n",
    "prob_lossfn = nn.BCELoss().to(device)\n",
    "bbox_lossfn = nn.MSELoss().to(device)\n",
    "\n",
    "optimizer = None\n",
    "\n",
    "if opt == \"Adam\":\n",
    "    print(\"Optimizer: Adam\")\n",
    "    optimizer = torch.optim.Adam(bnet.parameters(), lr=learning_rate, amsgrad=True)\n",
    "elif opt == \"SGD\":\n",
    "    print(\"Optimizer: SGD\")\n",
    "    optimizer = torch.optim.SGD(bnet.parameters(), lr=learning_rate, momentum=0.9)\n",
    "else:\n",
    "    print(\"Error\")\n",
    "\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_step, gamma=decay_rate)\n",
    "\n",
    "rl1, rl2 = 0, 0\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        \n",
    "        im, b_prob, b_box = data\n",
    "        \n",
    "        im = im.to(device)\n",
    "        b_prob = b_prob.float().to(device)\n",
    "        b_box = b_box.float().to(device)\n",
    "        \n",
    "        o_b_prob, o_b_box = bnet(im)\n",
    "        \n",
    "        o_b_prob = o_b_prob.float().squeeze()\n",
    "        o_b_box = o_b_box.float().squeeze()\n",
    "        \n",
    "        b_prob_l = prob_lossfn(o_b_prob, b_prob)\n",
    "        b_box_l = bbox_lossfn(o_b_box, b_box)\n",
    "        \n",
    "        rl1 += b_prob_l.item()\n",
    "        rl2 += b_box_l.item()\n",
    "\n",
    "        all_loss = b_prob_l + b_box_l\n",
    "        \n",
    "        if batch_idx % print_freq == print_freq-1:\n",
    "            \n",
    "            print(\n",
    "                \"ep: {}; bpl: {:.2f}; bbl: {:.2f};\".format(\n",
    "                    epoch, rl1/print_freq, rl2/print_freq\n",
    "                )\n",
    "            )\n",
    "            writer.add_scalar('bpl', rl1/print_freq, epoch)\n",
    "            writer.add_scalar('bbl', rl2/print_freq, epoch)\n",
    "            \n",
    "            rl1, rl2 = 0, 0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        all_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "print(\"finished training\")\n",
    "\n",
    "save_name = 'bnet.pt'\n",
    "torch.save(bnet.state_dict(), save_name)\n",
    "print('Saved model at {}'.format(save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(valid_ds)\n",
    "b_err = 0\n",
    "bt, bp = [], []\n",
    "\n",
    "for idx in range(0, total):\n",
    "    \n",
    "    obp, obb = bnet(valid_ds[idx][0].unsqueeze(0).to(device))\n",
    "    obp = obp.squeeze()\n",
    "    \n",
    "    aop = obp[0]\n",
    "    obp = int(obp[0] > obp[1])\n",
    "\n",
    "    tbp = int(b_prob_v[idx][0] > b_prob_v[idx][1])\n",
    "\n",
    "    b_err += (obp != tbp)\n",
    "        \n",
    "    if idx % 20 == 0:\n",
    "        plt.imshow(transforms.ToPILImage()(valid_ds[idx][0]))\n",
    "        plt.show()\n",
    "        print(\"tb: {}; pb: {:.1f}\".format(int(tbp), aop.cpu().detach().item()))\n",
    "        print(\"body: \" + str(np.rint(obb.cpu().detach().squeeze().numpy())))\n",
    "\n",
    "print(\"total: {}\".format(total))\n",
    "print(\"body accuracy: {:.1f}%\".format(100*(total-b_err)/total))\n",
    "\n",
    "\"\"\"\n",
    "p, r, f1 = utils.f1_score(truth, pred, 0)\n",
    "print(\"precision: {:.2f}, recall: {:.2f}, f1: {:.2f}\".format(p, r, f1))\n",
    "print(\"valid_ds length: {}\".format(len(valid_ds)))\n",
    "print(\"age dist: \", end='')\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = 'bnet.pt'\n",
    "torch.save(bnet.state_dict(), save_name)\n",
    "print('Saved model at {}'.format(save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
